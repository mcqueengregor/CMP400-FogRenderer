#version 430
layout (local_size_x = 1, local_size_y = 9, local_size_z = 1) in;
layout (rgba32f, binding = 1) uniform image3D imgOutput;

// Based on Wronski's chapter on volumetric fog in GPU Pro 360, chapt. 18:

#define PI 3.141592653589793238462643383279
#define MAX_LIGHTS 8

layout (std140) uniform Matrices
{
	mat4 proj;
	mat4 view;

	mat4 invViewProj;
	mat4 prevViewProj;
	mat4 currentViewProj;
} u_matrices;

struct PointLight
{
    vec3 position;
    vec3 diffuse;

	float radius;

    float constant;
    float linear;
    float quadratic;
};

struct Ray
{
	vec3 origin;
	vec3 direction;
};

struct RaySphereResults
{
	bool results;
	float t0;
	float t1;
};

// Camera data uniforms:
uniform vec3	u_cameraPos;
uniform vec3	u_cameraForward;
uniform vec2	u_cameraPlanes;

uniform vec3 u_fogTexSize;	// Added since imageSize() seems to return zeroes at random, for some reason.

// Fog data uniforms:
uniform vec3	u_albedo;
uniform float	u_scatteringCoefficient;
uniform float	u_absorptionCoefficient;
uniform vec2	u_fogHeightRange;
uniform float	u_phaseGParam;
uniform float	u_fogDensity;
uniform float	u_lightIntensity;
uniform int		u_frameIndex;

// Noise data uniforms:
uniform float	u_noiseFreq;
uniform vec3	u_noiseOffset;

// Light data uniforms:
uniform int			u_numActiveLights;
uniform float		u_lightFarPlane;
uniform PointLight	u_pointLights[MAX_LIGHTS];
uniform mat4		u_lightMatrices[6 * MAX_LIGHTS];

// Texture samplers:
uniform sampler2DArray	u_pointShadowmapArray;
uniform sampler3D		u_previousFrameFog;
uniform sampler2D		u_LUT;

// Controls:
uniform bool	u_useHetFog;
uniform bool	u_useJitter;
uniform bool	u_useTemporal;
uniform bool	u_useLUT;
uniform bool	u_KorH;		// 'false' = use Hoobler LUT, 'true' = use Kovalovs LUT.
uniform bool	u_linOrExp;	// 'false' = use exponential distribution, 'true' = use linear distribution.

uniform int u_shadowMapTechnique;

// Values match "ShadowMapTechnique" enum in App.h:
#define STANDARD 0
#define VSM 1
#define ESM 2

/* UTILITY FUNCTIONS: ---------------------------------------------------------------------------------- */

// Noise function is from Ken Perlin's Improved Noise implementation: https://cs.nyu.edu/~perlin/noise/
// Permuation of pseudo-random vector gradients:
const int perm[] = { 151,160,137,91,90,15,
   131,13,201,95,96,53,194,233,7,225,140,36,103,30,69,142,8,99,37,240,21,10,23,
   190, 6,148,247,120,234,75,0,26,197,62,94,252,219,203,117,35,11,32,57,177,33,
   88,237,149,56,87,174,20,125,136,171,168, 68,175,74,165,71,134,139,48,27,166,
   77,146,158,231,83,111,229,122,60,211,133,230,220,105,92,41,55,46,245,40,244,
   102,143,54, 65,25,63,161, 1,216,80,73,209,76,132,187,208, 89,18,169,200,196,
   135,130,116,188,159,86,164,100,109,198,173,186, 3,64,52,217,226,250,124,123,
   5,202,38,147,118,126,255,82,85,212,207,206,59,227,47,16,58,17,182,189,28,42,
   223,183,170,213,119,248,152, 2,44,154,163, 70,221,153,101,155,167, 43,172,9,
   129,22,39,253, 19,98,108,110,79,113,224,232,178,185, 112,104,218,246,97,228,
   251,34,242,193,238,210,144,12,191,179,162,241, 81,51,145,235,249,14,239,107,
   49,192,214, 31,181,199,106,157,184, 84,204,176,115,121,50,45,127, 4,150,254,
   138,236,205,93,222,114,67,29,24,72,243,141,128,195,78,66,215,61,156,180
   };

float fade(float t)
{
	return t * t * t * (t * (t * 6 - 15) + 10);
}

float noiseLerp(float t, float a, float b)
{
	return a + t * (b - a);
}

float grad(int hash, float x, float y, float z)
{
	int h = hash & 15;
	float	u = h < 8 ? x : y,
			v = h < 4 ? y : h==12 || h==14 ? x : z;
	return ((h & 1) == 0 ? u : -u) + ((h & 2) == 0 ? v : -v);
}

float perlinNoise(vec3 p)
{
	int X = int(floor(p.x)) & 255,
		Y = int(floor(p.y)) & 255,
		Z = int(floor(p.z)) & 255;

	// Isolate decimal values of p:
	p.x -= floor(p.x);
	p.y -= floor(p.y);
	p.z -= floor(p.z);

	float	u = fade(p.x),
			v = fade(p.y),
			w = fade(p.z);

	int A = perm[X  ] + Y, AA = perm[A] + Z, AB = perm[A+1] + Z,
		B = perm[X+1] + Y, BA = perm[B] + Z, BB = perm[B+1] + Z;

	return noiseLerp(w,		noiseLerp(v,	noiseLerp(u,	grad(perm[AA  ],	p.x,	p.y,	p.z		),
															grad(perm[BA  ],	p.x-1,	p.y,	p.z		)),
											noiseLerp(u,	grad(perm[AB  ],	p.x,	p.y-1,	p.z		),
															grad(perm[BB  ],	p.x-1,	p.y-1,	p.z		))),
							noiseLerp(v,	noiseLerp(u,	grad(perm[AA+1],	p.x,	p.y,	p.z-1	),
															grad(perm[BA+1],	p.x-1,	p.y,	p.z-1	)),
											noiseLerp(u,	grad(perm[AB+1],	p.x,	p.y-1,	p.z-1	),
															grad(perm[BB+1],	p.x-1,	p.y-1,	p.z-1	))));
}

float invLerp(float a, float b, float v)
{
	return (v - a) / (b - a);
}

float remap(float iMin, float iMax, float oMin, float oMax, float val)
{
	float t = invLerp(iMin, iMax, val);
	return mix(oMin, oMax, t);
}

bool floatEqual(float a, float b)
{
	const float e = 1E-8;
	return abs(a - b) < e;
}

bool vectorEqual(vec3 a, vec3 b)
{
	return floatEqual(a.x, b.x) && floatEqual(a.y, b.y) && floatEqual(a.z, b.z);
}

float halton(float index, uint base)
{
	float r = 0.0f;
	float f = 1.0f;

	while (index > 0.0f)
	{
		f /= base;
		r += f * mod(index, float(base));
		index = floor(index / float(base));
	}
	return r;
}

/* ----------------------------------------------------------------------------------------------------- */

float getFroxelDepth(float slice)
{
	const float C = 8.0;
	const float Q = 1.0;

	return pow(2, (slice + Q * C) / C) - pow(2, Q);
}

float getSliceThickness(uint slice)
{
	return getFroxelDepth(slice + 1) - getFroxelDepth(slice);
}


float getSliceIndex(float depth)
{
	const float ln2 = 0.6931471806;	// ln(2).
	return (8.0 * log((depth + 2.0) / 2.0)) / ln2;
}

bool outsideShadowmapBounds(vec3 projectedCoords)
{
	// Return whether projected NDC coords are within a light's frustum or not (i.e. if 0 < pCoords < 1):
	return projectedCoords.x < 0.0 || projectedCoords.x > 1.0 || projectedCoords.y < 0.0 || projectedCoords.y > 1.0
		|| projectedCoords.z > 1.0;
}

float calcShadow(uint lightIndex, vec3 worldPos)
{
	/*
		When considering the lighting for a froxel from a given light, how does shadowing get taken into account?
		Each light knows about its surroundings, and its associated shadowmap details when froxels would be in this
		light's shadow. If one froxel is in a light's shadow, it may or may not be in the shadow of other lights as
		well.
		Because of this, each froxel needs to check whether it is in shadow for each light. 
	*/

	// Iterate through all layers of shadowmap texture array for the current light:
	for (uint i = 6 * lightIndex; i < 6 * lightIndex + 6; ++i)
	{
		// Transform world position to light space:
		vec4 lightSpacePos = u_lightMatrices[i] * vec4(worldPos, 1.0);

		// Perform perspective division:
		vec3 projectedCoords = lightSpacePos.xyz / lightSpacePos.w;

		// Transform from [-1,1] range to [0,1] range:
		projectedCoords =  0.5 * projectedCoords + 0.5;

		// If projected position is within light frustum, perform shadow test:
		if (!outsideShadowmapBounds(projectedCoords))
		{
			// Get depth of closest occluder from shadowmap, scaled to [0, farPlane (squared)] range:
			vec2 moments = texture(u_pointShadowmapArray, vec3(projectedCoords.xy, float(i))).rg;
			moments.x *= u_lightFarPlane;
			moments.y *= u_lightFarPlane * u_lightFarPlane;
			
			vec3 lightDir = worldPos - u_pointLights[0].position;
			float currentDepth = length(lightDir);

			const float bias = 0.0;

			if (u_shadowMapTechnique == STANDARD)
				return currentDepth > moments.x + bias ? 0.0 : 1.0;

			else if (u_shadowMapTechnique == VSM)
			{
				float p = step(currentDepth, moments.x + bias);

				float variance = max(moments.y - moments.x * moments.x, 0.00002);
				float d = currentDepth - moments.x;

				float pMax = variance / (variance + d * d);
				return max(p, pMax);
			}
			else if (u_shadowMapTechnique == ESM)
				return clamp(exp(-1.0 * (currentDepth - moments.x)), 0.0, 1.0);
		}
	}

	// If point isn't within any light frustum, assume it's fully lit:
	return 1.0;
}

// Compute thread ID to world position logic adapted from https://github.com/diharaw/volumetric-lighting/blob/main/src/shaders/common.glsl:
float getFroxelThicknessExp(uint z)
{
	const float near = u_cameraPlanes.x, far = u_cameraPlanes.y;
	float farOverNear = far / near;
	return near * pow(farOverNear, (z + 1) / (u_fogTexSize.z - 1)) - near * pow(farOverNear, z / (u_fogTexSize.z - 1));
}

float getFroxelThicknessLin()
{
	const float near = u_cameraPlanes.x, far = u_cameraPlanes.y;
	const int numThreads = int(u_fogTexSize.z) - 1;
	return (far - near) / numThreads;
}

vec3 getWorldPos(uvec3 globalThreadID, float jitter, mat4 invViewProj)
{
	const float near = u_cameraPlanes.x, far = u_cameraPlanes.y;
	float farOverNear = far / near;
	
	float viewZExp;
	vec3 uv;

	viewZExp = near * pow(farOverNear, (globalThreadID.z + jitter) / (u_fogTexSize.z - 1));
	uv = vec3(globalThreadID.xy / u_fogTexSize.xy, viewZExp / far);

	// Get NDC from UV coords (convert to exponential z-depth distribution from linear compute ID):
	float ndcZ = (1.0 / uv.z - farOverNear) / (1.0 - farOverNear);
	vec3 ndc;

	ndc = 2.0 * vec3(uv.xy, ndcZ) - 1.0;

	vec4 world = invViewProj * vec4(ndc, 1.0);
	world.xyz /= world.w;

	// If a linear froxel depth distribution is used, adjust depth from exponential to linear:
	if (u_linOrExp)
	{
		// Calculate camera's up right and up vectors:
		vec3 right = normalize(cross(vec3(0.0, 1.0, 0.0), u_cameraForward));
		vec3 up = normalize(cross(right, u_cameraForward));

		vec3 view = vec3(dot(world.xyz, right), dot(world.xyz, up), dot(world.xyz, u_cameraForward));
		view.z = near * globalThreadID.z * getFroxelThicknessLin();

		vec3 world = transpose(mat3(u_matrices.view)) * -view;
	}

	return world.xyz;
}

vec3 getUVCoords(vec3 worldPos, mat4 viewProj)
{
	const float near = u_cameraPlanes.x, far = u_cameraPlanes.y;
	float farOverNear = far / near;

	vec4 ndc = viewProj * vec4(worldPos, 1.0);
	ndc.xyz /= ndc.w;

	vec3 uv = ndc.xyz * 0.5 + 0.5;

	if (u_linOrExp)
	{
		uv.z = invLerp(near, far, dot(u_cameraForward, worldPos - u_cameraPos));
	}
	else
	{
		float uvZ = 1.0 / ((1.0 - farOverNear) * uv.z + farOverNear);
		vec2 params = vec2(u_fogTexSize.z / log2(farOverNear), -(u_fogTexSize.z * log2(near) / log2(farOverNear)));
		uv.z = max(log2(uvZ * far) * params.x + params.y, 0.0) / u_fogTexSize.z;
	}

	return uv;
}

float phaseHG(uint lightIndex, vec3 worldPos, float g)
{
	vec3 lightDir = u_pointLights[lightIndex].position - worldPos;
	return 1 / (4 * PI) * (1 - g * g) / pow(1 + g * g - 2 * g * dot(u_cameraForward, normalize(lightDir)), 3 / 2);
}

// Get lighting intensity from point light (diffuse only):
vec3 calcPointLight(uint lightIndex, vec3 worldPos)
{
    // Calculate attenuation:
    float dist = length(u_pointLights[lightIndex].position - worldPos);
    float attenuation = 1.0 / (u_pointLights[lightIndex].constant + u_pointLights[lightIndex].linear * dist + u_pointLights[lightIndex].quadratic * (dist * dist));    

    return u_pointLights[lightIndex].diffuse * attenuation * u_lightIntensity;
}

/* KOVALOVS LUT SAMPLING: ------------------------------------------------------------------------------ */
bool raySphereIntersection(Ray froxelRay, uint lightIndex, float lightRadius, out float t0, out float t1)
{
	vec3 froxelToLight = u_pointLights[lightIndex].position - froxelRay.origin;
	float tc = dot(froxelToLight, froxelRay.direction);
	float lSqr = dot(froxelToLight, froxelToLight);

	float dSqr = abs(tc * tc - lSqr);

	if (dSqr > lightRadius * lightRadius)
		return false;

	float t1c = sqrt(lightRadius * lightRadius - dSqr);

	t0 = tc - t1c;
	t1 = tc + t1c;

	return true;
}

vec4 getKovalovsUVCoords(Ray froxelRay, uint lightIndex, float lightRadius, vec3 point0, vec3 point1)
{
	vec3 ab = point0 - u_pointLights[lightIndex].position;
	vec3 ac = point1 - u_pointLights[lightIndex].position;

	vec3 abNorm = normalize(ab);
	vec3 acNorm = normalize(ac);

	vec2 uv0 = vec2(0.0);
	vec2 uv1 = vec2(0.0);

	// If light's position lies on froxel ray or either intersection point-to-light vector is zero vector,
	// get UV coordinates along the upwards centre line:
	float dotResult = abs(dot(abNorm, acNorm));
	if (floatEqual(dotResult, 1.0) || vectorEqual(ab, vec3(0.0)) || vectorEqual(ac, vec3(0.0)))
	{
		if (dot(ab, froxelRay.direction) > 0.0)
			uv0 = vec2(0.5, 0.5 + ((length(ab) / lightRadius) * 0.5));
		else
			uv0 = vec2(0.5, 0.5 - ((length(ab) / lightRadius) * 0.5));

		if (dot(ac, froxelRay.direction) > 0.0)
			uv1 = vec2(0.5, 0.5 + ((length(ac) / lightRadius) * 0.5));
		else
			uv1 = vec2(0.5, 0.5 - ((length(ac) / lightRadius) * 0.5));

		return vec4(uv0.xy, uv1.xy);
	}
	
	// If angle between both intersection-to-light vectors is 0, then view ray is at a tangent to the
	// light sphere and there is no normal to define a plane, but the UV coords are both (0.0, 0.5):
	if (floatEqual(dot(abNorm, acNorm), 1.0))
		return vec4(0.0, 0.5, 0.0, 0.5);

	vec3 n = normalize(cross(ab, ac));
	vec3 nXv = normalize(cross(froxelRay.direction, n));

	uv0.x = dot(nXv, ab) / lightRadius;
	uv0.y = dot(froxelRay.direction, ab) / lightRadius;
	
	uv1.x = dot(nXv, ac) / lightRadius;
	uv1.y = dot(froxelRay.direction, ac) / lightRadius;

	uv0 = 0.5 * uv0 + 0.5;
	uv1 = 0.5 * uv1 + 0.5;

	return vec4(uv0.xy, uv1.xy);
}

float sampleKovalovsLUT(Ray froxelRay, float froxelThickness, uint lightIndex)
{
	const float lightRadius = u_pointLights[lightIndex].radius;
	float t0, t1;
	vec4 uvPair = vec4(0.0);

	if (raySphereIntersection(froxelRay, lightIndex, lightRadius, t0, t1))
	{
		// If first intersection is behind ray origin, check second intersection:
		if (t0 < 0.0)
		{
			// If second intersection is also behind ray origin, there are no intersections:
			if (t1 < 0.0)
			{
				return 0.0;
			}
			else
			{
				const vec3 iPoint = froxelRay.origin + froxelRay.direction * t1;

				// If second intersection is in front of froxel end, use froxel start and intersection point:
				if (t1 < froxelThickness)
					uvPair = getKovalovsUVCoords(froxelRay, lightIndex, lightRadius, froxelRay.origin, iPoint);
				// If second intersection is further away than froxel end, use froxel start and end:
				else
					uvPair = getKovalovsUVCoords(froxelRay, lightIndex, lightRadius, froxelRay.origin, froxelRay.origin + froxelRay.direction * froxelThickness);
			}
		}
		else
		{
			const vec3 iPoint0 = froxelRay.origin + froxelRay.direction * t0;
			const vec3 iPoint1 = froxelRay.origin + froxelRay.direction * t1;

			// If second intersection is in front of froxel end, use both intersection points:
			if (t1 < froxelThickness)
				uvPair = getKovalovsUVCoords(froxelRay, lightIndex, lightRadius, iPoint0, iPoint1);
			// If first intersection is in front of froxel end, use first intersection and froxel end:
			else if (t0 < froxelThickness)
				uvPair = getKovalovsUVCoords(froxelRay, lightIndex, lightRadius, iPoint0, froxelRay.origin + froxelRay.direction * froxelThickness);
			// If both intersections are behind froxel end, light doesn't intersect this froxel:
			else
				return 0.0;
		}
	}

	// Sample Kovalovs LUT with UV coords pair, return difference of scattering intensities:
	const float scattering0 = texture(u_LUT, uvPair.xy).r;
	const float scattering1 = texture(u_LUT, uvPair.zw).r;

	return abs(scattering0 - scattering1);
}

/* HOOBLER LUT SAMPLING: ------------------------------------------------------------------------------- */
vec3 sampleHooblerLUT(vec3 worldPos, uint lightIndex)
{
	const float lightRadius = u_pointLights[lightIndex].radius;
	vec3 lightToCamera = u_cameraPos - u_pointLights[lightIndex].position;
	float lightDist = length(lightToCamera);
	vec3 cameraToFroxel = normalize(worldPos - u_cameraPos);

	float t0 = max(lightDist - lightRadius, 0.0);
	float tRange = lightRadius + lightDist - t0;

	vec2 uv = vec2((lightDist - t0) / tRange, acos(-dot(normalize(lightToCamera), cameraToFroxel)) / PI);
	vec4 scattering = texture(u_LUT, uv);

	return scattering.rgb * scattering.a;
}

void main()
{
	// Get jitter for the current thread with Halton sequences, tranformed to [-0.5, 0.5] range:
	float jitter;

	if (u_useJitter)
		jitter = halton(u_frameIndex, 3);
	else
		jitter = 0.0;

	vec3 jitteredWorldPos = getWorldPos(gl_GlobalInvocationID, jitter, u_matrices.invViewProj);
	float thickness;
	
	if (u_linOrExp)
		thickness = getFroxelThicknessLin();
	else
		thickness = getFroxelThicknessExp(gl_GlobalInvocationID.z);

	float scattering = u_scatteringCoefficient * u_fogDensity;
	float absorption = u_absorptionCoefficient * u_fogDensity;

	if (u_useHetFog)
	{
		float density = perlinNoise((jitteredWorldPos + u_noiseOffset) * u_noiseFreq) /* + remapped height stuff */;

		// Transform noise from [-1,1] range to [0,1] range:
		density = density * 0.5 + 0.5;

		// Calculate scattering and absorption for this froxel:
		scattering *= density;
		absorption *= density;
	}

	vec3 lighting = vec3(0.0);

	// Accumulate lighting at this froxel:
	for (uint i = 0; i < u_numActiveLights; ++i)
	{
		vec3 light;
		
		if (!u_useLUT)
			light = calcPointLight(i, jitteredWorldPos) * phaseHG(i, jitteredWorldPos, u_phaseGParam) * calcShadow(i, jitteredWorldPos);
		else
		{
			// Sample from Kovalovs' LUT (true):
			if (u_KorH)
			{
				Ray froxelRay;
				froxelRay.origin = jitteredWorldPos;
				froxelRay.direction = normalize(jitteredWorldPos - u_cameraPos);

				light = sampleKovalovsLUT(froxelRay, thickness, i).rrr;
			}
			// Sample from Hoobler's LUT (false):
			else
			{
				light = sampleHooblerLUT(jitteredWorldPos, i);
			}

			light *= u_pointLights[i].diffuse * u_lightIntensity * calcShadow(i, jitteredWorldPos);
		}

		lighting += light;
	}

	// Tint accumulated lighting with fog albedo colour:
	lighting *= u_albedo;

	vec4 results = vec4(lighting * scattering, scattering + absorption);

	// Reproject to previous frame's results, if the unjittered world position can be projected to previous frame blend results:
	if (u_useTemporal)
	{
		vec3 unjitteredWorldPos = getWorldPos(gl_GlobalInvocationID, 0.0, u_matrices.invViewProj);
		vec3 blendUV = getUVCoords(unjitteredWorldPos, u_matrices.prevViewProj);

		// If UV coordinates are within previous frame's frustum, blend results:
		if (all(greaterThanEqual(blendUV, vec3(0.0))) && all(lessThanEqual(blendUV, vec3(1.0))))
		{
			vec4 previousFrameResults = texture(u_previousFrameFog, blendUV);

			results = mix(results, previousFrameResults, 0.95);
		}
	}

	// Write results to output texture:
	imageStore(imgOutput, ivec3(gl_GlobalInvocationID), results);
}